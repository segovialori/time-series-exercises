{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting \n",
    "\n",
    "![extrapolating](https://imgs.xkcd.com/comics/extrapolating.png)\n",
    "\n",
    "In this lesson, we will practice forecasting using the following methods:  \n",
    "\n",
    "- Last observed value  \n",
    "- Simple average  \n",
    "- Moving average  \n",
    "- Holt's Linear Trend  \n",
    "- Previous cycle  \n",
    "\n",
    "______________________________\n",
    "\n",
    "\n",
    "We will walk through steps from previous lessons to get the data ready to model\n",
    "\n",
    "- Acquire data: prepare.acquire_store_data()  \n",
    "- Prepare data: prepare.prep_store_data()  \n",
    "- Split data: prepare.split_store_data()  \n",
    "\n",
    "Then we will forecast and evaluate using each method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#viz\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "#for presentation purposes\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#working with dates\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt \n",
    "\n",
    "#evaluated performance using rmse\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#holts linear trend model\n",
    "from statsmodels.tsa.api import Holt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sale_id</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sale_date</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>2013-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_id</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sale_amount</th>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_brand</th>\n",
       "      <td>Riceland</td>\n",
       "      <td>Riceland</td>\n",
       "      <td>Riceland</td>\n",
       "      <td>Riceland</td>\n",
       "      <td>Riceland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_name</th>\n",
       "      <td>Riceland American Jazmine Rice</td>\n",
       "      <td>Riceland American Jazmine Rice</td>\n",
       "      <td>Riceland American Jazmine Rice</td>\n",
       "      <td>Riceland American Jazmine Rice</td>\n",
       "      <td>Riceland American Jazmine Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_price</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_address</th>\n",
       "      <td>12125 Alamo Ranch Pkwy</td>\n",
       "      <td>12125 Alamo Ranch Pkwy</td>\n",
       "      <td>12125 Alamo Ranch Pkwy</td>\n",
       "      <td>12125 Alamo Ranch Pkwy</td>\n",
       "      <td>12125 Alamo Ranch Pkwy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_zipcode</th>\n",
       "      <td>78253</td>\n",
       "      <td>78253</td>\n",
       "      <td>78253</td>\n",
       "      <td>78253</td>\n",
       "      <td>78253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_city</th>\n",
       "      <td>San Antonio</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>San Antonio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_state</th>\n",
       "      <td>TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>TX</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            0                               1  \\\n",
       "sale_id                                     1                               2   \n",
       "sale_date                          2013-01-01                      2013-01-02   \n",
       "store_id                                    1                               1   \n",
       "item_id                                     1                               1   \n",
       "sale_amount                                13                              11   \n",
       "item_brand                           Riceland                        Riceland   \n",
       "item_name      Riceland American Jazmine Rice  Riceland American Jazmine Rice   \n",
       "item_price                               0.84                            0.84   \n",
       "store_address          12125 Alamo Ranch Pkwy          12125 Alamo Ranch Pkwy   \n",
       "store_zipcode                           78253                           78253   \n",
       "store_city                        San Antonio                     San Antonio   \n",
       "store_state                                TX                              TX   \n",
       "\n",
       "                                            2                               3  \\\n",
       "sale_id                                     3                               4   \n",
       "sale_date                          2013-01-03                      2013-01-04   \n",
       "store_id                                    1                               1   \n",
       "item_id                                     1                               1   \n",
       "sale_amount                                14                              13   \n",
       "item_brand                           Riceland                        Riceland   \n",
       "item_name      Riceland American Jazmine Rice  Riceland American Jazmine Rice   \n",
       "item_price                               0.84                            0.84   \n",
       "store_address          12125 Alamo Ranch Pkwy          12125 Alamo Ranch Pkwy   \n",
       "store_zipcode                           78253                           78253   \n",
       "store_city                        San Antonio                     San Antonio   \n",
       "store_state                                TX                              TX   \n",
       "\n",
       "                                            4  \n",
       "sale_id                                     5  \n",
       "sale_date                          2013-01-05  \n",
       "store_id                                    1  \n",
       "item_id                                     1  \n",
       "sale_amount                                10  \n",
       "item_brand                           Riceland  \n",
       "item_name      Riceland American Jazmine Rice  \n",
       "item_price                               0.84  \n",
       "store_address          12125 Alamo Ranch Pkwy  \n",
       "store_zipcode                           78253  \n",
       "store_city                        San Antonio  \n",
       "store_state                                TX  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('store_item_demand.csv')\n",
    "df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. sale_date to datetime\n",
    "2. sort values by date\n",
    "3. set index\n",
    "4. new field: dollars_sold = sale_amount * item_price\n",
    "5. rename sale_amount to items_sold to make the two columns easier to understand what the data represents. \n",
    "6. resample daily (The original granularity is daily, but there are multiple records of the same days across multiple stores.)\n",
    "7. remove leap days!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will resample to daily, but essentially what we are doing is grouping by the day and aggregating using sum. The original granularity is daily, but there are multiple records of the same days across multiple stores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how maggie writes a function:\n",
    "#convert the sale date to datetime format\n",
    "df['ds'] = pd.to_datetime(df.sale_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort values by date\n",
    "df.sort_values('ds').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set index\n",
    "df = df.set_index('ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dollars_sold'] = df.sale_amount * df.item_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['dollars_sold', 'sale_amount', 'item_price']].head()\n",
    "df[['dollars_sold', 'sale_amount', 'item_price']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename sale amount ot items sold and drop original column of sale amount\n",
    "df = df.assign(item_sold = df.sale_amount).drop(columns=['sale_amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate or resample daily by summing dollars and items sold\n",
    "df_resampled = df.resample('d')[['dollars_sold', 'item_sold']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove leap day\n",
    "df_resampled[df_resampled.index != '2016-02-29' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(df):\n",
    "    \"\"\"\n",
    "    This function takes in a dataframe and returnsa dataframe with\n",
    "    the dates as index, aggregated by summing at the daily level,\n",
    "    changing the sale amount column name to be item sold, creating\n",
    "    a new feature of dollars_sold which is sale_amount * item_price\n",
    "    and removing the leap day.\n",
    "    \"\"\"\n",
    "    return (df.assign(ds = pd.to_datetime(df.sale_date)).\n",
    "            # sort values by date\n",
    "            sort_values('ds').\n",
    "            # create dollars_sold column\n",
    "            assign(dollars_sold = df.sale_amount * df.item_price).\n",
    "            # sale_amount to be items_sold\n",
    "            assign(items_sold = df.sale_amount).\n",
    "            # aggregate daily by summing the values\n",
    "            groupby(['ds'])[['dollars_sold', 'items_sold']].sum().\n",
    "            # set index to date\n",
    "            reset_index().set_index('ds')\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prep_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove leap days\n",
    "\n",
    "df = df[df.index != '2016-02-29']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split\n",
    "\n",
    "1. We will use the training proportion method to split.    \n",
    "2. Identify the total length of the dataframe and multiply by `train_prop` to get the number of rows that equates to the first x% of the dataframe, which equates to the first x% of the time covered in the data.   (`x = train_prop * 100`)  \n",
    "3. Select row indices from 0 up to the index representing x-percentile for train, and from the index representing x-percentile through the end of the dataframe for test. In both of these, we will reset the index in order to return dataframes sorted by datetime.  \n",
    "4. Return train and test dataframes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(df) * .5)\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_size = int(len(df) * .3)\n",
    "validate_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = int(len(df) - train_size - validate_size)\n",
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_end_index = train_size + validate_size\n",
    "validate_end_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use those values to split our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[: train_size]\n",
    "validate = df[train_size:validate_end_index]\n",
    "test = df[validate_end_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verify Splits**\n",
    "\n",
    "Does the length of each df equate to the length of the original df? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train) + len(validate) + len(test) == len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the first row of original df equate to the first row of train? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(1) == train.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the last row of train the day before the first row of validate? And the same for validate to test? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([train.tail(1), validate.head(1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([validate.tail(1), test.head(1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the last row of test the same as the last row of our original dataframe? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([test.tail(1), df.tail(1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot our data first, viewing where the data is split into train and test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(train[col])\n",
    "    plt.plot(validate[col])\n",
    "    plt.plot(test[col])\n",
    "    plt.ylabel(col)\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we try out different methods for forecasting sales and number of items sold, let's create a couple of functions that will be helpful in evaluating each of the methods that follow. \n",
    "\n",
    "`evaluate()` will compute the Mean Squared Error and the Rood Mean Squared Error to evaluate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(target_var):\n",
    "    rmse = round(sqrt(mean_squared_error(validate[target_var], yhat_df[target_var])), 0)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`plot_and_eval()` will use the evaluate function and also plot train and test values with the predicted values in order to compare performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_eval(target_var):\n",
    "    plt.figure(figsize = (12,4))\n",
    "    plt.plot(train[target_var], label='Train', linewidth=1)\n",
    "    plt.plot(validate[target_var], label='Validate', linewidth=1)\n",
    "    plt.plot(yhat_df[target_var])\n",
    "    plt.title(target_var)\n",
    "    rmse = evaluate(target_var)\n",
    "    print(target_var, '-- RMSE: {:.0f}'.format(rmse))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write `append_eval_df(model_type)` to append evaluation metrics for each model type, target variable, and metric type, along with the metric value into our `eval_df` data frame object. Which we will create an empty `eval_df` dataframe object to start. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dataframe\n",
    "eval_df = pd.DataFrame(columns=['model_type', 'target_var', 'rmse'])\n",
    "\n",
    "# function to store the rmse so that we can compare\n",
    "def append_eval_df(model_type, target_var):\n",
    "    rmse = evaluate(target_var)\n",
    "    d = {'model_type': [model_type], 'target_var': [target_var],\n",
    "        'rmse': [rmse]}\n",
    "    d = pd.DataFrame(d)\n",
    "    return eval_df.append(d, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast \n",
    "\n",
    "Forecasting is another word for predicting time series data. \n",
    "\n",
    "1. Last Observed Value\n",
    "2. Simple Average\n",
    "3. Moving Average\n",
    "4. Holt's Linear Trend\n",
    "5. Previous Cycle\n",
    "\n",
    "\n",
    "### Last observed value\n",
    "\n",
    "The simplest method for forecasting is to predict all future values to be the last observed value.  \n",
    "\n",
    "**Make Predictions**\n",
    "\n",
    "Dollars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dollars = round(train['dollars_sold'][-1:][0], 2)\n",
    "dollars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = train['items_sold'][-1:][0]\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df = pd.DataFrame({'dollars_sold': [dollars], \n",
    "                        'items_sold': [items]}, \n",
    "                      index = validate.index)\n",
    "\n",
    "yhat_df.head()\n",
    "yhat_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see, when peeking into yhat_df, that every predicted value is the same.  \n",
    "\n",
    "**Plot Actual vs. Predicted Values**\n",
    "\n",
    "Now, let's plot actual and predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_eval('dollars_sold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    plot_and_eval(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate** \n",
    "\n",
    "Evaluate using MSE and RMSE, and add evaluation metrics to `eval_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    eval_df = append_eval_df(model_type = 'last_observed_value', \n",
    "                             target_var = col)\n",
    "\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Average\n",
    "\n",
    "Take the simple average of historical values and use that value to predict future values.   \n",
    "\n",
    "This is a good option for an initial baseline. Every future datapoint (those in 'test') will be assigned the same value, and that value will be the overall mean of the values in train. \n",
    "\n",
    "**Make Predictions**\n",
    "\n",
    "Dollars: establishing the value of the prediction we will make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute simple average\n",
    "\n",
    "# plt.plot(train['dollars_sold'])\n",
    "dollars = round(train['dollars_sold'].mean(),2)\n",
    "dollars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Items: establishing the value of the prediction we will make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = round(train['items_sold'].mean(),2)\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply predictions to our observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions():\n",
    "    yhat_df = pd.DataFrame({'dollars_sold': [dollars],\n",
    "                           'items_sold': [items]}, \n",
    "                           index = validate.index)\n",
    "    return yhat_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df = make_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot Actual vs. Predicted Values**\n",
    "\n",
    "Now, let's plot and evaluate the performance of our time series model using **Simple Average**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    plot_and_eval(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate**\n",
    "\n",
    "Evaluate using MSE and RMSE, and add evaluation metrics to `eval_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    eval_df = append_eval_df(model_type='simple_average', \n",
    "                            target_var = col)\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Average\n",
    "\n",
    "In this example, we will use a 30-day moving average to forecast. In other words, the average over the last 30-days will be used as the forecasted value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['dollars_sold'].tail(30)\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(train['dollars_sold'].rolling(7).mean())\n",
    "plt.plot(train['dollars_sold'].rolling(30).mean())\n",
    "plt.plot(train['dollars_sold'].rolling(90).mean())\n",
    "plt.plot(train['dollars_sold'].rolling(120).mean())\n",
    "plt.plot(train['dollars_sold'], alpha=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate that the mean of the first 30 days \n",
    "# is equal to rolling(30) on day 30\n",
    "\n",
    "print(train['dollars_sold'].rolling(30).mean()[29])\n",
    "print(train['dollars_sold'].head(30).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = 30 \n",
    "\n",
    "dollars = round(train['dollars_sold'].rolling(period).mean()[-1], 2)\n",
    "items = round(train['items_sold'].rolling(period).mean()[-1], 2)\n",
    "\n",
    "print(dollars, items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df = make_predictions()\n",
    "yhat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot Actual vs. Predicted Values**\n",
    "\n",
    "Now, let's plot and evaluate the performance of our time series model using **Moving Average**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    plot_and_eval(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate**\n",
    "\n",
    "Evaluate using MSE and RMSE, and add evaluation metrics to `eval_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    eval_df = append_eval_df(model_type = '30d_moving_avg', \n",
    "                            target_var = col)\n",
    "\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try out several other values for periods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = [4, 12, 26, 52, 104]\n",
    "\n",
    "for p in periods: \n",
    "    dollars = round(train['dollars_sold'].rolling(p).mean()[-1], 2)\n",
    "    items = round(train['items_sold'].rolling(p).mean()[-1],2)\n",
    "    yhat_df = make_predictions()\n",
    "    model_type = str(p) + 'd_moving_avg'\n",
    "    for col in train.columns:\n",
    "        eval_df = append_eval_df(model_type = model_type, \n",
    "                                 target_var = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is best so far? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_items_rmse = eval_df[eval_df.target_var == 'items_sold']['rmse'].min()\n",
    "\n",
    "eval_df[eval_df.rmse == min_items_rmse]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holt's Linear Trend\n",
    "\n",
    "\n",
    "Exponential smoothing applied to both the average and the trend (slope).  \n",
    "\n",
    "- $\\alpha$ / smoothing_level: smoothing parameter for mean. Values closer to 1 will have less of a smoothing effect and will give greater weight to recent values.   \n",
    "- $\\beta$ / smoothing_slope: smoothing parameter for the slope. Values closer to 1 will give greater weight to recent slope/values. \n",
    "\n",
    "\n",
    "\n",
    "**Seasonal Decomposition**\n",
    "\n",
    "\n",
    "First, let's take a look at the seasonal decomposition for each target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    print(col, '\\n')\n",
    "    sm.tsa.seasonal_decompose(train[col].resample('W').mean()).plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Holt's Linear Trend\n",
    "\n",
    "**Make Predictions**\n",
    "\n",
    "Now, like we would when using sklearn, we will create the Holt object, fit the model, and make predictions. \n",
    "\n",
    "Holt: \n",
    "\n",
    "- exponential = True/False (exponential vs. linear growth, additive vs. multiplicative)\n",
    "- damped $\\phi$ = True/False: with Holt, forecasts will increase or decrease indefinitely into the future.  To avoid this, use the Damped trend method which has a damping parameter 0< ϕ <1. \n",
    "\n",
    "\n",
    "fit: \n",
    "\n",
    "- smoothing_level ($\\alpha$): value between (0,1)\n",
    "- smoothing_slope ($\\beta$): value between (0,1)\n",
    "- optimized: use the auto-optimization that allow statsmodels to automatically find an optimized value for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    model = Holt(train[col], exponential=False, damped=True)\n",
    "    model = model.fit(optimized=True)\n",
    "    yhat_items = model.predict(start = validate.index[0],\n",
    "                               end = validate.index[-1])\n",
    "    yhat_df[col] = round(yhat_items, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot Actual vs. Predicted Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    plot_and_eval(target_var = col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    eval_df = append_eval_df(model_type = 'holts_optimized', \n",
    "                            target_var = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.sort_values(by='rmse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do another model, changing some hyperparameters. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    model = Holt(train[col], exponential=False)\n",
    "    model = model.fit(smoothing_level=.1, \n",
    "                      smoothing_slope=.1, \n",
    "                      optimized=False)\n",
    "    yhat_items = model.predict(start = validate.index[0],\n",
    "                               end = validate.index[-1])\n",
    "    yhat_df[col] = round(yhat_items, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    plot_and_eval(target_var = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    eval_df = append_eval_df(model_type = 'holts_.1', \n",
    "                            target_var = col)\n",
    "eval_df.sort_values(by='rmse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Based on Previous Cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take all the 2016 data points, compute the daily delta, year-over-year, average that delta over all the days, and adding that average to the previous year's value on a day will give you the forecast for that day. \n",
    "\n",
    "If a primary cycle is weekly, then you may want to do this on a week-over-week cadence. \n",
    "\n",
    "In the below example:  \n",
    "1. Compute the 365 average year over year differences from 2013 through 2015\n",
    "2. Add that average delta to the values during 2015. \n",
    "3. Set the index in your yhat dataframe to represent the dates those predictions are make for. \n",
    "\n",
    "Let's get started....\n",
    "\n",
    "**Re-split data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[:'2015']\n",
    "validate = df['2016']\n",
    "test = df['2017']\n",
    "\n",
    "print(train.shape)\n",
    "print(validate.shape)\n",
    "print(test.shape)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the year-over-year difference for each day from 2013 to 2015\n",
    "# taking the mean, and then adding that value to the daily 2015 values. \n",
    "\n",
    "yhat_df = train['2015'] + train.diff(365).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's peek into the prediction we will make for 1/1/2016\n",
    "# by comparing the predicted value \n",
    "# (2015 value + year-over-year average difference)\n",
    "# to the actual 1/1/2016 value\n",
    "pd.concat([yhat_df.head(1), validate.head(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set yhat_df to index of validate\n",
    "\n",
    "yhat_df.index = validate.index\n",
    "\n",
    "yhat_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot and Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    plot_and_eval(target_var = col)\n",
    "    eval_df = append_eval_df(model_type = \"previous_year\", \n",
    "                            target_var = col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Which model did the best? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dollars_min_rmse = eval_df.groupby('target_var')['rmse'].min()[0]\n",
    "\n",
    "items_min_rmse = eval_df.groupby('target_var')['rmse'].min()[1]\n",
    "\n",
    "# find which model that is\n",
    "eval_df[((eval_df.rmse == dollars_min_rmse) | \n",
    "         (eval_df.rmse == items_min_rmse))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it out on our out-of-sample data\n",
    "\n",
    "We will be using train + validate to predict test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df = validate + train.diff(365).mean()\n",
    "yhat_df.index = test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_plot(target_var):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(train[target_var], label='train')\n",
    "    plt.plot(validate[target_var], label='validate')\n",
    "    plt.plot(test[target_var], label='test')\n",
    "    plt.plot(yhat_df[target_var], alpha=.5)\n",
    "    plt.title(target_var)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_dollars = sqrt(mean_squared_error(test['dollars_sold'], \n",
    "                                       yhat_df['dollars_sold']))\n",
    "\n",
    "rmse_items = sqrt(mean_squared_error(test['items_sold'], \n",
    "                                       yhat_df['items_sold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rmse-dollars_sold: ', rmse_dollars)\n",
    "print('rmse-items_sold: ', rmse_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    final_plot(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to predict 2018\n",
    "\n",
    "yhat_df = test + train.diff(365).mean()\n",
    "\n",
    "yhat_df.index = test.index + pd.Timedelta('1Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_plot(target_var):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(train[target_var], label='train')\n",
    "    plt.plot(validate[target_var], label='validate')\n",
    "    plt.plot(test[target_var], label='test')\n",
    "    plt.plot(yhat_df[target_var], alpha=.5)\n",
    "    plt.title(target_var)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    final_plot(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "The end result of this exercise should be a Jupyter notebook named `model`.\n",
    "\n",
    "Using [saas.csv](https://ds.codeup.com/saas.csv) or log data from API usage or store_item_sales\n",
    "\n",
    "1. Split data (train/test) and resample by any period, except daily, and aggregate using the sum. \n",
    "2. Forecast, plot and evaluate using each of the 4 parametric based methods we discussed:\n",
    "    - Simple Average\n",
    "    - Moving Average\n",
    "    - Holt's Linear Trend Model\n",
    "    - Based on previous year/month/etc., this is up to you.\n",
    "\n",
    "Optional: Using store item demand\n",
    "\n",
    "1. Predict 2018 total **monthly** sales for a single store and/or item by creating a model using prophet.\n",
    "2. Return a dataframe with the month, store_id, y-hat, and the confidence intervals (y-hat lower, y-hat upper).\n",
    "3. Plot the 2018 monthly sales predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
